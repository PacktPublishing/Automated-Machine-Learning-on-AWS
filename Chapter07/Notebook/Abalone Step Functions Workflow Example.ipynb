{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Workflow Automation using the Step Functions Data Science SDK\n",
    "\n",
    ">__NOTE:__ This Notebook uses the _Python 3 (Data Science)_ Kernel.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Pre-Requisites\n",
    "\n",
    "### Load the Step Functions Data Science Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install stepfunctions==2.2.0 sagemaker==2.49.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Basic CodeBuild Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "os.environ[\"MODEL_NAME\"] = \"abalone\"\n",
    "os.environ[\"PIPELINE_NAME\"] = \"abalone-cicd-pipeline\"\n",
    "os.environ[\"BUCKET_NAME\"] = f\"\"\"{boto3.client(\"ssm\").get_parameter(Name=\"PipelineBucketName\")[\"Parameter\"][\"Value\"]}\"\"\"\n",
    "os.environ[\"DATA_PREFIX\"] = \"abalone_data\"\n",
    "os.environ[\"EPOCHS\"] = \"200\"\n",
    "os.environ[\"BATCH_SIZE\"] = \"8\"\n",
    "os.environ[\"THRESHOLD\"] = \"2.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `write_and_run` Cell Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def custom_writefile(line, cell):\n",
    "    print(\"Writing {}\".format(line.split()[0]))\n",
    "    with open(line.split()[0], \"a\") as f:\n",
    "        f.write(cell)\n",
    "    print(\"Running Cell\")\n",
    "    get_ipython().run_cell(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Workflow Setup\n",
    "\n",
    "### Import Required Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "import io\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "import botocore\n",
    "import zipfile\n",
    "import json\n",
    "from time import gmtime, strftime, sleep\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import stepfunctions\n",
    "from stepfunctions import steps\n",
    "from stepfunctions.inputs import ExecutionInput\n",
    "from stepfunctions.steps import (\n",
    "    Chain,\n",
    "    ChoiceRule,\n",
    "    ModelStep,\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    "    TuningStep,\n",
    "    TransformStep,\n",
    "    Task,\n",
    "    EndpointConfigStep,\n",
    "    EndpointStep,\n",
    "    LambdaStep\n",
    ")\n",
    "from stepfunctions.template import TrainingPipeline\n",
    "from stepfunctions.template.utils import replace_parameters_with_jsonpath\n",
    "from stepfunctions.workflow import Workflow\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, Processor\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "sfn_client = boto3.client(\"stepfunctions\")\n",
    "lambda_client = boto3.client(\"lambda\")\n",
    "codepipeline_client = boto3.client(\"codepipeline\")\n",
    "ssm_client = boto3.client(\"ssm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Helper/Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `get_workflow_role` Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "def get_workflow_role():\n",
    "    try:\n",
    "        response = ssm_client.get_parameter(\n",
    "            Name=\"WorkflowRoleParameter\",\n",
    "        )\n",
    "        return response[\"Parameter\"][\"Value\"]\n",
    "    except ClientError as e:\n",
    "        error_message = e.response[\"Error\"][\"Message\"]\n",
    "        print(error_message)\n",
    "        raise Exception(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `update_lambda` Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "def update_lambda(name, zip_name):\n",
    "    lambda_client.update_function_code(\n",
    "        FunctionName=name,\n",
    "        ZipFile=open(zip_name, mode=\"rb\").read(),\n",
    "        Publish=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `get_lambda` Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "def get_lambda(name, bucket, description):\n",
    "    print(\"Creating Lambda Package \")\n",
    "    zip_name = f\"../artifacts/{name}.zip\"\n",
    "    lambda_src = f\"../artifacts/{name}.py\"\n",
    "    z = zipfile.ZipFile(zip_name, mode=\"w\")\n",
    "    z.write(lambda_src, arcname=lambda_src.split(\"/\")[-1])\n",
    "    z.close()\n",
    "    print(\"Uploading Lambda Package to S3 \")\n",
    "    S3Uploader.upload(\n",
    "        local_path=zip_name,\n",
    "        desired_s3_uri=f\"s3://{bucket}/lambda\",\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(f\"Creating Lambda Function '{name}' ...\")\n",
    "        lambda_client.create_function(\n",
    "            FunctionName=name,\n",
    "            Runtime=\"python3.8\",\n",
    "            Role=get_workflow_role(),\n",
    "            Handler=f\"{name}.lambda_handler\",\n",
    "            Code={\n",
    "                \"S3Bucket\": bucket,\n",
    "                \"S3Key\": f\"lambda/{name}.zip\"\n",
    "            },\n",
    "            Description=description,\n",
    "            Timeout=120,\n",
    "            MemorySize=128\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        print(f\"Lambda Function '{name}' already exists, re-creating ...\")\n",
    "        update_lambda(name, zip_name)\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `get_execution_id` Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "def get_execution_id(name=None):\n",
    "    try:\n",
    "        response = codepipeline_client.get_pipeline_state(name=name)\n",
    "        for stage in response[\"stageStates\"]:\n",
    "            if stage[\"stageName\"] == \"Build\":\n",
    "                for action in stage[\"actionStates\"]:\n",
    "                    if action[\"actionName\"] == \"BuildModel\":\n",
    "                        return stage[\"latestExecution\"][\"pipelineExecutionId\"]\n",
    "    except KeyError:\n",
    "        return strftime('%Y%m%d%H%M%S', gmtime())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Execution Parameters and Schema\n",
    "\n",
    "#### Workflow Paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "execution_id = get_execution_id(name=os.environ[\"PIPELINE_NAME\"])\n",
    "model = os.environ[\"MODEL_NAME\"]\n",
    "data_prefix = os.environ[\"DATA_PREFIX\"]\n",
    "model_prefix = execution_id\n",
    "bucket_name = os.environ[\"BUCKET_NAME\"]\n",
    "model_name = f\"{model}-{execution_id}\"\n",
    "training_job_name = f\"{model}-TrainingJob-{execution_id}\"\n",
    "preprocessing_job_name = f\"{model}-ProcessingJob-{execution_id}\"\n",
    "evaluation_job_name = f\"{model}-EvaluationJob-{execution_id}\"\n",
    "deeplearning_container_image = f\"763104351884.dkr.ecr.{region}.amazonaws.com/tensorflow-training:2.5.0-cpu-py37-ubuntu18.04-v1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow Execution Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "execution_input = ExecutionInput(\n",
    "    schema={\n",
    "        \"ModelName\": str,\n",
    "        \"PreprocessingJobName\": str,\n",
    "        \"TrainingJobName\": str,\n",
    "        \"EvaluationProcessingJobName\": str\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "s3_bucket_base_uri = f\"s3://{bucket_name}\"\n",
    "input_data = os.path.join(s3_bucket_base_uri,  data_prefix, \"raw/abalone.data\")\n",
    "output_data = os.path.join(s3_bucket_base_uri, data_prefix)\n",
    "preprocessed_training_data = os.path.join(output_data, \"input\", \"training\")\n",
    "preprocessed_testing_data = f\"{output_data}/testing\"\n",
    "model_data_s3_uri = f\"{s3_bucket_base_uri}/{model_prefix}/{training_job_name}/output/model.tar.gz\"\n",
    "output_model_evaluation_s3_uri = f\"{s3_bucket_base_uri}/{model_prefix}/{training_job_name}/evaluation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Data Processing Step\n",
    "\n",
    "### Data Processing Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../artifacts/preprocessing.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "prefix = \"/opt/ml\"\n",
    "processing_path = os.path.join(prefix, \"processing\")\n",
    "preprocessing_input_path = os.path.join(processing_path, \"input\")\n",
    "preprocessing_output_path = os.path.join(processing_path, \"output\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Preprocessing Data\")\n",
    "    column_names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole_weight\", \"shucked_weight\", \"viscera_weight\", \"shell_weight\", \"rings\"]\n",
    "    data = pd.read_csv(os.path.join(preprocessing_input_path, \"abalone.data\"), names=column_names)\n",
    "    y = data.rings.values.reshape(len(data), 1)\n",
    "    del data[\"rings\"]\n",
    "    print(\"Creating Catagorical Features\")\n",
    "    data = pd.get_dummies(data).to_numpy()\n",
    "    X = np.concatenate((y, data), axis=1)\n",
    "    print(\"Splitting Data into Training, Validation and, Test Datasets\")\n",
    "    training, validation, testing = np.split(X, [int(.8*len(X)), int(.95*len(X))])\n",
    "    pd.DataFrame(training).to_csv(os.path.join(preprocessing_output_path, \"training/training.csv\"), header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(os.path.join(preprocessing_output_path, \"training/validation.csv\"), header=False, index=False)\n",
    "    pd.DataFrame(testing).to_csv(os.path.join(preprocessing_output_path, \"testing/testing.csv\"), header=False, index=False)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Step Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    \"Pre-process Data\",\n",
    "    processor=SKLearnProcessor(\n",
    "        framework_version=\"0.23-1\",\n",
    "        role=role,\n",
    "        instance_type=\"ml.m5.xlarge\",\n",
    "        instance_count=1,\n",
    "        max_runtime_in_seconds=1200,\n",
    "    ),\n",
    "    job_name=execution_input[\"PreprocessingJobName\"],\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_data,\n",
    "            destination=\"/opt/ml/processing/input\",\n",
    "            input_name=\"input\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=sagemaker_session.upload_data(\n",
    "                path=\"../artifacts/preprocessing.py\",\n",
    "                bucket=bucket_name,\n",
    "                key_prefix=os.path.join(data_prefix, \"code\")\n",
    "            ),\n",
    "            destination=\"/opt/ml/processing/input/code\",\n",
    "            input_name=\"code\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "           source=\"/opt/ml/processing/output/training\",\n",
    "           destination=os.path.join(output_data, \"input\", \"training\"),\n",
    "           output_name=\"training\"\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/output/testing\",\n",
    "            destination=os.path.join(output_data, \"testing\"),\n",
    "            output_name=\"testing\"\n",
    "        )\n",
    "    ],\n",
    "    container_entrypoint=[\"python3\", \"/opt/ml/processing/input/code/preprocessing.py\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Model Training Step\n",
    "\n",
    "### TensorFlow Model Training Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../artifacts/model_training.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import preprocessing\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "    column_names = [\"rings\", \"length\", \"diameter\", \"height\", \"whole weight\", \"shucked weight\",\n",
    "                    \"viscera weight\", \"shell weight\", \"sex_F\", \"sex_I\", \"sex_M\"]\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--epochs', type=int, default=2)\n",
    "    parser.add_argument('--batch-size', type=int, default=8)\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--training', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "    args, _ = parser.parse_known_args()\n",
    "    epochs = args.epochs\n",
    "    batch_size = args.batch_size\n",
    "    training_path = args.training\n",
    "    model_path = args.model_dir\n",
    "    train_data = pd.read_csv(os.path.join(training_path, 'training.csv'), sep=',', names=column_names)\n",
    "    val_data = pd.read_csv(os.path.join(training_path, 'validation.csv'), sep=',', names=column_names)\n",
    "    train_y = train_data['rings'].to_numpy()\n",
    "    train_X = train_data.drop(['rings'], axis=1).to_numpy()\n",
    "    val_y = val_data['rings'].to_numpy()\n",
    "    val_X = val_data.drop(['rings'], axis=1).to_numpy()\n",
    "    train_X = preprocessing.normalize(train_X)\n",
    "    val_X = preprocessing.normalize(val_X)\n",
    "    network_layers = [\n",
    "            Dense(64, activation=\"relu\", kernel_initializer=\"normal\", input_dim=10),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(1, activation=\"linear\")\n",
    "        ]\n",
    "    model = Sequential(network_layers)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae', 'accuracy'])\n",
    "    model.summary()\n",
    "    model.fit(\n",
    "        train_X,\n",
    "        train_y,\n",
    "        validation_data=(val_X, val_y),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        shuffle=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Model Evaluation Format\n",
    "    model.save(os.path.join(model_path, 'model.h5'))\n",
    "    # TF Serving Format\n",
    "    model_version = 1\n",
    "    export_path = os.path.join(model_path, str(model_version))\n",
    "    tf.keras.models.save_model(\n",
    "        model,\n",
    "        export_path,\n",
    "        overwrite=True,\n",
    "        include_optimizer=True,\n",
    "        save_format=None,\n",
    "        signatures=None,\n",
    "        options=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Step Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    \"Model Training\",\n",
    "    estimator=TensorFlow(\n",
    "        entry_point='../artifacts/model_training.py',\n",
    "        role=role,\n",
    "        hyperparameters={\n",
    "            'epochs': int(os.environ['EPOCHS']),\n",
    "            'batch-size': int(os.environ['BATCH_SIZE']),\n",
    "        }, \n",
    "        train_instance_count=1,\n",
    "        train_instance_type='ml.m5.xlarge',\n",
    "        framework_version='2.4',\n",
    "        py_version=\"py37\",\n",
    "        script_mode=True,\n",
    "        output_path=os.path.join(s3_bucket_base_uri, model_prefix)\n",
    "    ),\n",
    "    data={\"training\": sagemaker.inputs.TrainingInput(preprocessed_training_data, content_type=\"csv\")},\n",
    "    job_name=execution_input[\"TrainingJobName\"],\n",
    "    wait_for_completion=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Model Evaluation Step\n",
    "\n",
    "### Model Evaluation Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../artifacts/evaluate.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = tf.keras.models.load_model(os.path.join(model_path, 'model.h5'))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(prefix, model):\n",
    "    column_names = [\"rings\", \"length\", \"diameter\", \"height\", \"whole weight\", \"shucked weight\",\n",
    "                    \"viscera weight\", \"shell weight\", \"sex_F\", \"sex_I\", \"sex_M\"]\n",
    "    input_path = os.path.join(prefix, \"processing/testing\")\n",
    "    output_path = os.path.join(prefix, \"processing/evaluation\")\n",
    "    predictions = []\n",
    "    truths = []\n",
    "    test_df = pd.read_csv(os.path.join(input_path, \"testing.csv\"), names=column_names)\n",
    "    y = test_df['rings'].to_numpy()\n",
    "    X = test_df.drop(['rings'], axis=1).to_numpy()\n",
    "    X = preprocessing.normalize(X)\n",
    "    for row in range(len(X)):\n",
    "        payload = [X[row].tolist()]\n",
    "        result = model.predict(payload)\n",
    "        print(result[0][0])\n",
    "        predictions.append(float(result[0][0]))\n",
    "        truths.append(float(y[row]))\n",
    "    report = {\n",
    "        \"GroundTruth\": truths,\n",
    "        \"Predictions\": predictions\n",
    "    }\n",
    "    with open(os.path.join(output_path, \"evaluation.json\"), \"w\") as f:\n",
    "        f.write(json.dumps(report))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Extracting model archive ...\")\n",
    "    prefix = \"/opt/ml\"\n",
    "    model_path = os.path.join(prefix, \"model\")\n",
    "    tarfile_path = os.path.join(prefix, \"processing/model/model.tar.gz\")\n",
    "    with tarfile.open(tarfile_path) as tar:\n",
    "        tar.extractall(path=model_path)\n",
    "    print(\"Loading Trained Model ...\")\n",
    "    model = load_model(model_path)\n",
    "    print(\"Evaluating Trained Model ...\")\n",
    "    evaluate_model(prefix, model)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Step Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "evaluation_step = ProcessingStep(\n",
    "    \"Model Evaluation\",\n",
    "    processor=Processor(\n",
    "        image_uri=deeplearning_container_image,\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.m5.xlarge\",\n",
    "        role=role,\n",
    "        max_runtime_in_seconds=1200\n",
    "    ),\n",
    "    job_name=execution_input[\"EvaluationProcessingJobName\"],\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=preprocessed_testing_data,\n",
    "            destination=\"/opt/ml/processing/testing\",\n",
    "            input_name=\"input\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=model_data_s3_uri,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "            input_name=\"model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=sagemaker_session.upload_data(\n",
    "                path=\"../artifacts/evaluate.py\",\n",
    "                bucket=bucket_name,\n",
    "                key_prefix=os.path.join(data_prefix, \"code\")\n",
    "            ),\n",
    "            destination=\"/opt/ml/processing/input/code\",\n",
    "            input_name=\"code\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=output_model_evaluation_s3_uri,\n",
    "            output_name=\"evaluation\"\n",
    "        )\n",
    "    ],\n",
    "    container_entrypoint=[\"python3\", \"/opt/ml/processing/input/code/evaluate.py\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Analyze Evaluation Metrics Step\n",
    "\n",
    "### Lambda Function (`lambda_handler()`) to Analyze Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../artifacts/analyze_results.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "import botocore\n",
    "import math\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    logger.debug(\"## Environment Variables ##\")\n",
    "    logger.debug(os.environ)\n",
    "    logger.debug(\"## Event ##\")\n",
    "    logger.debug(event)\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    if (\"Bucket\" in event):\n",
    "        bucket = event[\"Bucket\"]\n",
    "    else:\n",
    "        raise KeyError(\"S3 'Bucket' not found in Lambda event!\")\n",
    "    if (\"Key\" in event):\n",
    "        key = event[\"Key\"]\n",
    "    else:\n",
    "        raise KeyError(\"S3 'Key' not found in Lambda event!\")\n",
    "    logger.info(\"Downloading evlauation results file ...\")\n",
    "    json_file = json.loads(s3.get_object(Bucket = bucket, Key = key)['Body'].read())\n",
    "    logger.info(\"Analyzing Model Evaluation Results ...\")\n",
    "    y = json_file[\"GroundTruth\"]\n",
    "    y_hat = json_file[\"Predictions\"]\n",
    "    summation = 0\n",
    "    for i in range (0, len(y)):\n",
    "        squared_diff = (y[i] - y_hat[i])**2\n",
    "        summation += squared_diff\n",
    "    rmse = math.sqrt(summation/len(y))\n",
    "    logger.info(\"Root Mean Square Error: {}\".format(rmse))\n",
    "    logger.info(\"Done!\")\n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"Result\": rmse,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Evaluation Metrics Step Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "analyze_results_step = LambdaStep(\n",
    "    \"Analyze Evaluation Results\",\n",
    "    parameters={\n",
    "        \"FunctionName\": get_lambda(\n",
    "            \"analyze_results\",\n",
    "            bucket_name,\n",
    "            \"Analyze the results from the Model Evaluation\"\n",
    "        ),\n",
    "        \"Payload\": {\n",
    "            \"Bucket\": bucket_name,\n",
    "            \"Key\": f\"\"\"{model_prefix}/{training_job_name}/evaluation/evaluation.json\"\"\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Register Trained Model Step\n",
    "\n",
    "### Register Model Step Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    \"Register Trained Model\",\n",
    "    model=training_step.get_expected_model(),\n",
    "    model_name=execution_input[\"ModelName\"],\n",
    "    instance_type=\"ml.m5.large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Define the Step Functions Workflow\n",
    "\n",
    "### Define the Workflow _Failure_ States\n",
    "\n",
    "#### Workflow Failed State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "workflow_failed_state = stepfunctions.steps.states.Fail(\n",
    "    \"ML Workflow Failed\", cause=\"SageMakerProcessingJobFailed\"\n",
    ")\n",
    "catch_state = stepfunctions.steps.states.Catch(error_equals=[\"States.TaskFailed\"], next_step=workflow_failed_state)\n",
    "processing_step.add_catch(catch_state)\n",
    "training_step.add_catch(catch_state)\n",
    "evaluation_step.add_catch(catch_state)\n",
    "analyze_results_step.add_catch(catch_state)\n",
    "register_model_step.add_catch(catch_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation Failed State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "threshold_fail_state = stepfunctions.steps.states.Fail(\n",
    "    \"Model Evaluation Exceeds Threshold\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Workflow _Success_ States\n",
    "\n",
    "#### Model Evaluation Success State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "threshold_pass_state = stepfunctions.steps.states.Pass(\n",
    "    \"Model Evaluation Below Threshold\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Workflow _Choice_ States\n",
    "\n",
    "#### Model Evaluation Threshold Choice State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "check_threshold_step = steps.states.Choice(\n",
    "    \"Threshold Evaluation Check\"\n",
    ")\n",
    "threshold_rule = steps.choice_rule.ChoiceRule.NumericLessThan(\n",
    "    variable=analyze_results_step.output()['Payload']['Result'],\n",
    "    value=float(os.environ[\"THRESHOLD\"])\n",
    ")\n",
    "check_threshold_step.add_choice(rule=threshold_rule, next_step=threshold_pass_state)\n",
    "check_threshold_step.default_choice(next_step=threshold_fail_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denfine the Overall Workflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%custom_writefile ../workflow/main.py\n",
    "\n",
    "ml_workflow_graph = Chain(\n",
    "    [\n",
    "        processing_step,\n",
    "        training_step,\n",
    "        register_model_step,\n",
    "        evaluation_step,\n",
    "        analyze_results_step,\n",
    "        check_threshold_step\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Perform Workflow System Tests (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_workflow = Workflow(\n",
    "    name=\"abalone-workflow-unit-test\",\n",
    "    definition=ml_workflow_graph,\n",
    "    role=get_workflow_role(),\n",
    ")\n",
    "\n",
    "ml_workflow.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(ml_workflow.definition.to_json(pretty=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = ml_workflow.execute(\n",
    "    inputs={\n",
    "        \"ModelName\": model_name,\n",
    "        \"PreprocessingJobName\": preprocessing_job_name,\n",
    "        \"TrainingJobName\": training_job_name,\n",
    "        \"EvaluationProcessingJobName\": evaluation_job_name,\n",
    "    }\n",
    ")\n",
    "\n",
    "execution_output = execution.get_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_workflow.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Continuous Integration\n",
    "\n",
    "### Continuous Integration of the Workflow\n",
    "\n",
    ">__NOTE:__ Ensure all previous State Machines have been deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a ../workflow/main.py\n",
    "\n",
    "print(\"Creating ML Workflow\")\n",
    "ml_workflow = Workflow(\n",
    "    name=\"abalone-workflow\",\n",
    "    definition=ml_workflow_graph,\n",
    "    role=get_workflow_role(),\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"Creating Step Functions State Machine\")\n",
    "    ml_workflow.create()\n",
    "except sfn_client.exceptions.StateMachineAlreadyExists:\n",
    "    print(\"Found Existing State Machine, Updating the State Machine definition\")\n",
    "else:\n",
    "    ml_workflow.update(ml_workflow_graph)\n",
    "    time.sleep(120)\n",
    "\n",
    "print(\"Executing ML Workflow State Machine\")\n",
    "ml_workflow.execute(\n",
    "    inputs={\n",
    "        \"ModelName\": model_name,\n",
    "        \"PreprocessingJobName\": preprocessing_job_name,\n",
    "        \"TrainingJobName\": training_job_name,\n",
    "        \"EvaluationProcessingJobName\": evaluation_job_name\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### Save Execution Input Variables for Integration -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commit changes to the CodeCommit Repository to Start the Continuous Workflow**"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
