{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing how to simulate model quality inferences\n",
    "\n",
    "## Section 1 - Setup\n",
    "\n",
    "><div class=\"alert alert-block alert-info\"><b>NOTE: </b>Recommend using an <em>ml.m5.large</em> instance type and, <em>Python 3 (Data Science)</em> kernel to train the <b>CTGAN</b> model.</div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install CTGAN\n",
    "#!pip install CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import boto3\n",
    "import io\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from time import sleep\n",
    "from threading import Thread\n",
    "\n",
    "from sagemaker import get_execution_role, session, Session, image_uris\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.processing import ProcessingJob\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::500842391574:role/SageMaker\n",
      "Region: us-east-2\n"
     ]
    }
   ],
   "source": [
    "# Get Execution role\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn:\", role)\n",
    "\n",
    "region = session.boto_region_name\n",
    "print(\"Region:\", region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Testing Bucket: proddeploymentstage-prodappl-logss3bucket004b0f70-1y2budxvotxwc\n",
      "Image URI: 777275614652.dkr.ecr.us-east-2.amazonaws.com/sagemaker-model-monitor-analyzer\n",
      "Capture path: s3://proddeploymentstage-prodappl-logss3bucket004b0f70-1y2budxvotxwc/endpoint-data-capture\n",
      "Ground truth path: s3://proddeploymentstage-prodappl-logss3bucket004b0f70-1y2budxvotxwc/ground-truth-data/2021-05-02-18-26-22\n"
     ]
    }
   ],
   "source": [
    "# Setup S3 bucket parmaters for the production logs bucket\n",
    "bucket = 'proddeploymentstage-prodappl-logss3bucket004b0f70-1y2budxvotxwc'\n",
    "print(\"Inference Testing Bucket:\", bucket)\n",
    "\n",
    "# S3 prefixes\n",
    "data_capture_prefix = 'endpoint-data-capture'\n",
    "s3_capture_upload_path = f's3://{bucket}/{data_capture_prefix}'\n",
    "ground_truth_upload_path = f's3://{bucket}/ground-truth-data/{datetime.now():%Y-%m-%d-%H-%M-%S}'\n",
    "\n",
    "# Get the model monitor image\n",
    "monitor_image_uri = image_uris.retrieve(framework=\"model-monitor\", region=region)\n",
    "\n",
    "print(\"Image URI:\", monitor_image_uri)\n",
    "print(f\"Capture path: {s3_capture_upload_path}\")\n",
    "print(f\"Ground truth path: {ground_truth_upload_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2 - Recreate Baseline Data\n",
    "\n",
    "We will re-create the Model Quality baseline job (even though it was already created by the CDK Pipeline) to see the output of the SageMaker SDK when calling `create_monitoring_schedule()`, as well as, to leverage the resultant constraints when creating the monitoring schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline data uri: s3://proddeploymentstage-prodappl-logss3bucket004b0f70-1y2budxvotxwc/baselining/data\n",
      "Baseline results uri: s3://proddeploymentstage-prodappl-logss3bucket004b0f70-1y2budxvotxwc/baselining/results\n"
     ]
    }
   ],
   "source": [
    "# Set up the locations for capturing the baseline results\n",
    "# This should already be in place from the CDK Pipeline,\n",
    "# with the `baseline.csv` already there\n",
    "baseline_prefix = 'baselining'\n",
    "baseline_data_prefix = baseline_prefix + '/data'\n",
    "baseline_results_prefix = baseline_prefix + '/results'\n",
    "\n",
    "baseline_dataset_uri = f's3://{bucket}/{baseline_data_prefix}'\n",
    "baseline_results_uri = f's3://{bucket}/{baseline_results_prefix}'\n",
    "print(f'Baseline data uri: {baseline_dataset_uri}')\n",
    "print(f'Baseline results uri: {baseline_results_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new baseline job\n",
    "from sagemaker.model_monitor import ModelQualityMonitor\n",
    "from sagemaker.model_monitor import EndpointInput\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "# Create the model quality monitoring object\n",
    "model_quality_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the model quality baseline job\n",
    "baseline_job_name = f'abalone-baseline-{datetime.utcnow():%Y-%m-%d-%H%M}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the baseline suggestion job. \n",
    "# Specify problem type, in this case Regression, and provide other required attributes.\n",
    "job = model_quality_monitor.suggest_baseline(\n",
    "    job_name=baseline_job_name,\n",
    "    baseline_dataset=baseline_dataset_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri = baseline_results_uri,\n",
    "    problem_type='Regression',\n",
    "    inference_attribute= \"prediction\",\n",
    "    ground_truth_attribute= \"label\"\n",
    ")\n",
    "job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Generated Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = model_quality_monitor.latest_baselining_job\n",
    "binary_metrics = baseline_job.baseline_statistics().body_dict[\"regression_metrics\"]\n",
    "pd.json_normalize(binary_metrics).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Generated Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(baseline_job.suggested_constraints().body_dict[\"regression_constraints\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3 - Create Inferene Data to Test the Model Quality Monitor\n",
    "\n",
    "Model Quality Monitoring needs two additional inputs - predictions made by the deployed model endpoint and the ground truth data to be provided by the model consuming application. Since you already enabled data capture on the endpoint, prediction data is captured in S3. The ground truth data depends on the what the model is predicting and what the business use case is.\n",
    "\n",
    "### Gerating Synthetic Abalone data\n",
    "\n",
    "In order to generate prediction data we will need to create fake \"new\" data. To accomplish this, we will use the CTGAN package and train it on the \"raw\" abaloen dataset. We will create $300$ samples of fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex  length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   shell_weight  rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# 'raw' data column names\n",
    "names = [\n",
    "    'sex',\n",
    "    'length',\n",
    "    'diameter',\n",
    "    'height',\n",
    "    'whole_weight',\n",
    "    'shucked_weight',\n",
    "    'viscera_weight',\n",
    "    'shell_weight',\n",
    "    'rings'\n",
    "]\n",
    "\n",
    "# Location of the 'raw' data\n",
    "bucket = 'data-us-east-2-500842391574'\n",
    "key = 'input/raw/abalone.csv'\n",
    "obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "raw_data = pd.read_csv(io.BytesIO(obj['Body'].read()), encoding='utf8', names=names)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctgan import CTGANSynthesizer\n",
    "\n",
    "# Fit the CTGAN model, declaring the 'sex'column as discrete variables\n",
    "ctgan = CTGANSynthesizer()\n",
    "ctgan.fit(raw_data, ['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 300 samples from the CTGAN model\n",
    "samples = ctgan.sample(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.523992</td>\n",
       "      <td>0.407881</td>\n",
       "      <td>0.139516</td>\n",
       "      <td>0.828742</td>\n",
       "      <td>0.359367</td>\n",
       "      <td>0.180594</td>\n",
       "      <td>0.238831</td>\n",
       "      <td>9.933684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.120093</td>\n",
       "      <td>0.099240</td>\n",
       "      <td>0.041827</td>\n",
       "      <td>0.490389</td>\n",
       "      <td>0.221963</td>\n",
       "      <td>0.109614</td>\n",
       "      <td>0.139203</td>\n",
       "      <td>3.224169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.153000</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.329000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length     diameter       height  whole_weight  shucked_weight  \\\n",
       "count  4177.000000  4177.000000  4177.000000   4177.000000     4177.000000   \n",
       "mean      0.523992     0.407881     0.139516      0.828742        0.359367   \n",
       "std       0.120093     0.099240     0.041827      0.490389        0.221963   \n",
       "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
       "25%       0.450000     0.350000     0.115000      0.441500        0.186000   \n",
       "50%       0.545000     0.425000     0.140000      0.799500        0.336000   \n",
       "75%       0.615000     0.480000     0.165000      1.153000        0.502000   \n",
       "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
       "\n",
       "       viscera_weight  shell_weight        rings  \n",
       "count     4177.000000   4177.000000  4177.000000  \n",
       "mean         0.180594      0.238831     9.933684  \n",
       "std          0.109614      0.139203     3.224169  \n",
       "min          0.000500      0.001500     1.000000  \n",
       "25%          0.093500      0.130000     8.000000  \n",
       "50%          0.171000      0.234000     9.000000  \n",
       "75%          0.253000      0.329000    11.000000  \n",
       "max          0.760000      1.005000    29.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the raw data\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.541224</td>\n",
       "      <td>0.403590</td>\n",
       "      <td>0.154495</td>\n",
       "      <td>0.725746</td>\n",
       "      <td>0.382409</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.221105</td>\n",
       "      <td>9.493333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.140408</td>\n",
       "      <td>0.127399</td>\n",
       "      <td>0.045346</td>\n",
       "      <td>0.492354</td>\n",
       "      <td>0.225591</td>\n",
       "      <td>0.126288</td>\n",
       "      <td>0.142308</td>\n",
       "      <td>3.309552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.101786</td>\n",
       "      <td>0.035434</td>\n",
       "      <td>-0.005030</td>\n",
       "      <td>-0.113143</td>\n",
       "      <td>-0.030926</td>\n",
       "      <td>-0.019424</td>\n",
       "      <td>-0.026072</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.457475</td>\n",
       "      <td>0.331583</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.397777</td>\n",
       "      <td>0.223960</td>\n",
       "      <td>0.107950</td>\n",
       "      <td>0.118371</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.549092</td>\n",
       "      <td>0.424468</td>\n",
       "      <td>0.158490</td>\n",
       "      <td>0.725064</td>\n",
       "      <td>0.348765</td>\n",
       "      <td>0.198957</td>\n",
       "      <td>0.205575</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.642550</td>\n",
       "      <td>0.497184</td>\n",
       "      <td>0.186664</td>\n",
       "      <td>1.015252</td>\n",
       "      <td>0.508372</td>\n",
       "      <td>0.296405</td>\n",
       "      <td>0.318155</td>\n",
       "      <td>11.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.786797</td>\n",
       "      <td>0.633748</td>\n",
       "      <td>0.243380</td>\n",
       "      <td>2.400230</td>\n",
       "      <td>1.254820</td>\n",
       "      <td>0.572425</td>\n",
       "      <td>0.840583</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           length    diameter      height  whole_weight  shucked_weight  \\\n",
       "count  300.000000  300.000000  300.000000    300.000000      300.000000   \n",
       "mean     0.541224    0.403590    0.154495      0.725746        0.382409   \n",
       "std      0.140408    0.127399    0.045346      0.492354        0.225591   \n",
       "min      0.101786    0.035434   -0.005030     -0.113143       -0.030926   \n",
       "25%      0.457475    0.331583    0.129630      0.397777        0.223960   \n",
       "50%      0.549092    0.424468    0.158490      0.725064        0.348765   \n",
       "75%      0.642550    0.497184    0.186664      1.015252        0.508372   \n",
       "max      0.786797    0.633748    0.243380      2.400230        1.254820   \n",
       "\n",
       "       viscera_weight  shell_weight       rings  \n",
       "count      300.000000    300.000000  300.000000  \n",
       "mean         0.203390      0.221105    9.493333  \n",
       "std          0.126288      0.142308    3.309552  \n",
       "min         -0.019424     -0.026072    3.000000  \n",
       "25%          0.107950      0.118371    8.000000  \n",
       "50%          0.198957      0.205575    9.000000  \n",
       "75%          0.296405      0.318155   11.250000  \n",
       "max          0.572425      0.840583   22.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the sample data\n",
    "samples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the samples as fake abalone data\n",
    "samples.to_csv('fake-abalone.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process the Synthetic Abalone Data\n",
    "\n",
    "Since the synthetic data is based on the \"raw\" Abalone dataset and, in order to execute inferences against the production endpoint, we will need to transform the data into to the format our model has been trained upon. To do this, we will follow the same proceedure for preprocessing the origional Abalone data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    'sex': str,\n",
    "    'length': np.float64,\n",
    "    'diameter': np.float64,\n",
    "    'height': np.float64,\n",
    "    'whole_weight': np.float64,\n",
    "    'shucked_weight': np.float64,\n",
    "    'viscera_weight': np.float64,\n",
    "    'shell_weight': np.float64\n",
    "}\n",
    "label_column_dtype = {'rings': np.float64}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "# Preprocess the data\n",
    "df = pd.read_csv(\n",
    "    'fake-abalone.csv',\n",
    "    dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype)\n",
    ")\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Since we get a headerless CSV file we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    'sex',\n",
    "    'length',\n",
    "    'diameter',\n",
    "    'height',\n",
    "    'whole_weight',\n",
    "    'shucked_weight',\n",
    "    'viscera_weight',\n",
    "    'shell_weight',\n",
    "]\n",
    "label_column = 'rings'\n",
    "\n",
    "\n",
    "# Set up the processing pipeline for Numerical feature scaling\n",
    "numeric_features = list(feature_columns_names)\n",
    "numeric_features.remove('sex')\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Set up the processing pipeline for categorical encoding\n",
    "categorical_features = ['sex']\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the transformer\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocess the data\n",
    "y = df.pop('rings')\n",
    "X_pre = preprocess.fit_transform(df)\n",
    "y_pre = y.to_numpy().reshape(len(y), 1)\n",
    "\n",
    "header = [\n",
    "    'length',\n",
    "    'diameter',\n",
    "    'height',\n",
    "    'whole_weight',\n",
    "    'shucked_weight',\n",
    "    'viscera_weight',\n",
    "    'shell_weight',\n",
    "    'sex_F',\n",
    "    'sex_I',\n",
    "    'sex_M'\n",
    "]\n",
    "\n",
    "# Create the inference dataset\n",
    "# pd.DataFrame(X_pre).to_csv('inference-data.csv', header=False, index=False)\n",
    "pd.DataFrame(X_pre).to_csv('inference-data.csv', header=header, index=False)\n",
    "\n",
    "# Create the ground trutch dataset\n",
    "pd.DataFrame(y_pre).to_csv('ground-truth.csv', header=['label'], index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have the following syntehtic data files:\n",
    "- `fake-abalone.csv`: Synthic \"raw\" abalone data.\n",
    "- `inference-data.csv`: Preprocessed data to generate predictions from the Production Endpoint.\n",
    "- `ground-truth.csv`: The ground truth labels from the synthetic data wich to compare the quality of the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4 - Setup continuous model monitoring to identify model quality drift \n",
    "\n",
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Inferences uding the `FormHandler` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def invoke_endpoint(ep_name, file_name):    \n",
    "#     with open(file_name, 'r') as f:\n",
    "#         i = 0\n",
    "#         for row in f:\n",
    "#             payload = row.rstrip('\\n')\n",
    "#             response = session.sagemaker_runtime_client.invoke_endpoint(\n",
    "#                 EndpointName=endpoint_name,\n",
    "#                 ContentType='text/csv', \n",
    "#                 Body=payload,\n",
    "#                 InferenceId=str(i), # unique ID per row\n",
    "#             )[\"Body\"].read()\n",
    "#             i += 1\n",
    "#             sleep(1)\n",
    "            \n",
    "# def invoke_endpoint_forever():\n",
    "#     while True:\n",
    "#         invoke_endpoint(endpoint_name, 'inference-data.csv')\n",
    "        \n",
    "# thread = Thread(target = invoke_endpoint_forever)\n",
    "# thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View captured data stored in Amazon S3. You should expect to see different files from different time periods organized based on the hour in which the invocation occurred. The format of the Amazon S3 path is:\n",
    "\n",
    "`s3://{destination-bucket-prefix}/{endpoint-name}/{variant-name}/yyyy/mm/dd/hh/filename.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for captures to show up"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'endpoint_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-185741d329d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Waiting for captures to show up\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#5 Minutes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcapture_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS3Downloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{s3_capture_upload_path}/{endpoint_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcapture_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcapture_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS3Downloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapture_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'endpoint_name' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Waiting for captures to show up\", end=\"\")\n",
    "for _ in range(300): #5 Minutes\n",
    "    capture_files = sorted(S3Downloader.list(f\"{s3_capture_upload_path}/{endpoint_name}\"))\n",
    "    if capture_files:\n",
    "        capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")\n",
    "        capture_record = json.loads(capture_file[0])\n",
    "        if \"inferenceId\" in capture_record[\"eventMetadata\"]:\n",
    "            break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    sleep(1)\n",
    "print()\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files[-3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the contents of a single capture file. Here you should see all the data captured in an Amazon SageMaker specific JSON-line formatted file. Take a quick peek at the first few lines in the captured file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(capture_file[-3:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the contents of a single line is present below in a formatted JSON file so that you can observe a little better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(capture_record, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Prototyping: Load the Fake Data\n",
    "\n",
    "## Simulate the __original__ form request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.030321</td>\n",
       "      <td>0.625345</td>\n",
       "      <td>-0.510023</td>\n",
       "      <td>-0.450467</td>\n",
       "      <td>0.967696</td>\n",
       "      <td>0.999419</td>\n",
       "      <td>0.044743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.002049</td>\n",
       "      <td>0.786466</td>\n",
       "      <td>1.001100</td>\n",
       "      <td>0.618082</td>\n",
       "      <td>-0.152741</td>\n",
       "      <td>0.580372</td>\n",
       "      <td>0.328322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016244</td>\n",
       "      <td>0.820966</td>\n",
       "      <td>-0.197747</td>\n",
       "      <td>-0.794957</td>\n",
       "      <td>-0.589634</td>\n",
       "      <td>-0.228903</td>\n",
       "      <td>-0.567400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.349017</td>\n",
       "      <td>-0.596164</td>\n",
       "      <td>0.063278</td>\n",
       "      <td>-0.144823</td>\n",
       "      <td>-0.197446</td>\n",
       "      <td>0.964422</td>\n",
       "      <td>-0.722974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.657094</td>\n",
       "      <td>-0.250455</td>\n",
       "      <td>-0.939538</td>\n",
       "      <td>-0.121472</td>\n",
       "      <td>0.071549</td>\n",
       "      <td>-1.062272</td>\n",
       "      <td>1.034768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.823343</td>\n",
       "      <td>0.713829</td>\n",
       "      <td>0.693015</td>\n",
       "      <td>0.416776</td>\n",
       "      <td>-0.182791</td>\n",
       "      <td>0.692146</td>\n",
       "      <td>1.319292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.878026</td>\n",
       "      <td>0.215635</td>\n",
       "      <td>0.395211</td>\n",
       "      <td>0.463293</td>\n",
       "      <td>1.352296</td>\n",
       "      <td>0.077992</td>\n",
       "      <td>0.433733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-0.294669</td>\n",
       "      <td>-0.448046</td>\n",
       "      <td>-0.248960</td>\n",
       "      <td>0.338348</td>\n",
       "      <td>0.341708</td>\n",
       "      <td>0.653577</td>\n",
       "      <td>1.098421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-0.626096</td>\n",
       "      <td>-0.702165</td>\n",
       "      <td>-0.503231</td>\n",
       "      <td>-0.403328</td>\n",
       "      <td>-1.242498</td>\n",
       "      <td>-1.525372</td>\n",
       "      <td>-0.422840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-0.665780</td>\n",
       "      <td>0.558968</td>\n",
       "      <td>-0.639835</td>\n",
       "      <td>0.731653</td>\n",
       "      <td>0.474620</td>\n",
       "      <td>-0.130605</td>\n",
       "      <td>0.169079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       length  diameter    height  whole_weight  shucked_weight  \\\n",
       "0    1.030321  0.625345 -0.510023     -0.450467        0.967696   \n",
       "1    1.002049  0.786466  1.001100      0.618082       -0.152741   \n",
       "2    0.016244  0.820966 -0.197747     -0.794957       -0.589634   \n",
       "3    0.349017 -0.596164  0.063278     -0.144823       -0.197446   \n",
       "4   -0.657094 -0.250455 -0.939538     -0.121472        0.071549   \n",
       "..        ...       ...       ...           ...             ...   \n",
       "295  0.823343  0.713829  0.693015      0.416776       -0.182791   \n",
       "296  0.878026  0.215635  0.395211      0.463293        1.352296   \n",
       "297 -0.294669 -0.448046 -0.248960      0.338348        0.341708   \n",
       "298 -0.626096 -0.702165 -0.503231     -0.403328       -1.242498   \n",
       "299 -0.665780  0.558968 -0.639835      0.731653        0.474620   \n",
       "\n",
       "     viscera_weight  shell_weight  sex_F  sex_I  sex_M  \n",
       "0          0.999419      0.044743    1.0    0.0    0.0  \n",
       "1          0.580372      0.328322    1.0    0.0    0.0  \n",
       "2         -0.228903     -0.567400    0.0    1.0    0.0  \n",
       "3          0.964422     -0.722974    1.0    0.0    0.0  \n",
       "4         -1.062272      1.034768    0.0    0.0    1.0  \n",
       "..              ...           ...    ...    ...    ...  \n",
       "295        0.692146      1.319292    1.0    0.0    0.0  \n",
       "296        0.077992      0.433733    0.0    0.0    1.0  \n",
       "297        0.653577      1.098421    0.0    0.0    1.0  \n",
       "298       -1.525372     -0.422840    0.0    1.0    0.0  \n",
       "299       -0.130605      0.169079    0.0    0.0    1.0  \n",
       "\n",
       "[300 rows x 10 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('inference-data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'length': 1.0303210547,\n",
       " 'diameter': 0.6253454581,\n",
       " 'height': -0.5100226899,\n",
       " 'whole_weight': -0.4504671329,\n",
       " 'shucked_weight': 0.9676957699,\n",
       " 'viscera_weight': 0.9994186984,\n",
       " 'shell_weight': 0.0447432706,\n",
       " 'sex_F': 1.0,\n",
       " 'sex_I': 0.0,\n",
       " 'sex_M': 0.0}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#body = json.dumps(json.loads(df['json'][0]))\n",
    "body = json.loads(df.iloc[0].to_json())\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['json'] = df.apply(lambda x: x.to_json(), axis=1)\n",
    "# body = json.loads(df['json'][0])\n",
    "# body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://3fdb5qj5qf.execute-api.us-east-2.amazonaws.com/api/predict'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = 'https://3fdb5qj5qf.execute-api.us-east-2.amazonaws.com/'+'api/predict'\n",
    "api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"content-type\":\"application/json; charset=UTF-8\", \"inference-id\":\"0\"}\n",
    "response = requests.post(api, headers=headers, data = json.dumps(body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_api(api, file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    i = 0\n",
    "    for row in range(len(df)):\n",
    "        headers = {\"content-type\":\"application/json; charset=UTF-8\", \"inference-id\": str(i)}\n",
    "        body = json.loads(df.iloc[row].to_json())\n",
    "        response = requests.post(api, headers=headers, data = json.dumps(body))\n",
    "        i += 1\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_api('https://3fdb5qj5qf.execute-api.us-east-2.amazonaws.com/'+'api/predict', 'inference-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for captures to show up..........\n",
      "Found Capture Files:\n",
      "s3://proddeploymentstage-prodappl-logss3bucket004b0f70-1y2budxvotxwc/endpoint-data-capture/abalone-prod-endpoint/AllTraffic/2021/05/02/19/31-15-074-8ac7f32d-3d86-4be7-974f-f7c8d19f5801.jsonl\n",
      " s3://proddeploymentstage-prodappl-logss3bucket004b0f70-1y2budxvotxwc/endpoint-data-capture/abalone-prod-endpoint/AllTraffic/2021/05/02/19/32-14-822-3211d613-80b8-4e49-8bba-73f8a3fb175f.jsonl\n",
      " s3://proddeploymentstage-prodappl-logss3bucket004b0f70-1y2budxvotxwc/endpoint-data-capture/abalone-prod-endpoint/AllTraffic/2021/05/02/19/32-15-945-c2853a92-9f78-45ff-af6f-ca75f522c77a.jsonl\n"
     ]
    }
   ],
   "source": [
    "print(\"Waiting for captures to show up\", end=\"\")\n",
    "for _ in range(10):\n",
    "    capture_files = sorted(S3Downloader.list(f\"{s3_capture_upload_path}/abalone-prod-endpoint\"))\n",
    "    if capture_files:\n",
    "        capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")\n",
    "        capture_record = json.loads(capture_file[0])\n",
    "        if \"inferenceId\" in capture_record[\"eventMetadata\"]:\n",
    "            break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    sleep(1)\n",
    "print()\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"-0.2946686172,-0.4480458169,-0.2489597399,0.3383480237,0.3417079097,0.6535765649,1.0984211402,0.0,0.0,1.0\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"11.083495\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"d16d55ff-a9e7-43c0-b5a0-a33c250f004f\",\"inferenceTime\":\"2021-05-02T19:32:36Z\"},\"eventVersion\":\"0\"}\n",
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"-0.6260961569,-0.7021653362,-0.5032310101,-0.4033278206,-1.2424982885,-1.5253719385,-0.4228395077,0.0,1.0,0.0\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"21.360489\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"85770182-7b50-48a7-b225-93589603227b\",\"inferenceTime\":\"2021-05-02T19:32:37Z\"},\"eventVersion\":\"0\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(capture_file[-3:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"captureData\": {\n",
      "    \"endpointInput\": {\n",
      "      \"observedContentType\": \"text/csv\",\n",
      "      \"mode\": \"INPUT\",\n",
      "      \"data\": \"0.9513159831,0.6444342339,0.1541224377,0.5611244216,-0.360546775,1.0808794014,-0.706852323,0.0,0.0,1.0\",\n",
      "      \"encoding\": \"CSV\"\n",
      "    },\n",
      "    \"endpointOutput\": {\n",
      "      \"observedContentType\": \"text/csv; charset=utf-8\",\n",
      "      \"mode\": \"OUTPUT\",\n",
      "      \"data\": \"16.620396\",\n",
      "      \"encoding\": \"CSV\"\n",
      "    }\n",
      "  },\n",
      "  \"eventMetadata\": {\n",
      "    \"eventId\": \"b40ad35e-8daa-4a03-ac17-068a235b2041\",\n",
      "    \"inferenceTime\": \"2021-05-02T19:32:15Z\"\n",
      "  },\n",
      "  \"eventVersion\": \"0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(capture_record, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.4'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.2'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
